// Verilated -*- C++ -*-
// DESCRIPTION: Verilator output: Design implementation internals
// See Vbiriscv_top.h for the primary calling header

#include "verilated.h"
#include "verilated_dpi.h"

#include "Vbiriscv_top__Syms.h"
#include "Vbiriscv_top_riscv_core__SC1_SD1_E1.h"

VL_ATTR_COLD void Vbiriscv_top_riscv_core__SC1_SD1_E1___ctor_var_reset(Vbiriscv_top_riscv_core__SC1_SD1_E1* vlSelf) {
    if (false && vlSelf) {}  // Prevent unused
    Vbiriscv_top__Syms* const __restrict vlSymsp VL_ATTR_UNUSED = vlSelf->vlSymsp;
    VL_DEBUG_IF(VL_DBG_MSGF("+        Vbiriscv_top_riscv_core__SC1_SD1_E1___ctor_var_reset\n"); );
    // Body
    vlSelf->__PVT__clk_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__rst_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_data_rd_i = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mem_d_accept_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_ack_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_error_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_resp_tag_i = VL_RAND_RESET_I(11);
    vlSelf->__PVT__mem_i_accept_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_valid_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_error_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_inst_i = VL_RAND_RESET_Q(64);
    vlSelf->__PVT__intr_i = VL_RAND_RESET_I(1);
    vlSelf->__PVT__reset_vector_i = VL_RAND_RESET_I(32);
    vlSelf->__PVT__cpu_id_i = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mem_d_addr_o = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mem_d_data_wr_o = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mem_d_rd_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_wr_o = VL_RAND_RESET_I(4);
    vlSelf->__PVT__mem_d_cacheable_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_req_tag_o = VL_RAND_RESET_I(11);
    vlSelf->__PVT__mem_d_invalidate_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_writeback_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_d_flush_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_rd_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_flush_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_invalidate_o = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mem_i_pc_o = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_writeback_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_opcode_rd_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__mul_opcode_rd_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__fetch1_instr_csr_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_d_exec1_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_flush_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__lsu_opcode_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_exec0_source_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch_in_priv_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__csr_opcode_rb_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__writeback_mem_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__writeback_div_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__csr_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_csr_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_ifetch_inst_w = VL_RAND_RESET_Q(64);
    vlSelf->__PVT__mmu_lsu_error_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_exec0_is_call_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mul_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec0_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_mxr_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec0_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode0_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode0_ra_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_ifetch_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_opcode_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_writeback_exception_w = VL_RAND_RESET_I(6);
    vlSelf->__PVT__branch_exec1_is_call_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_is_not_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_d_exec0_priv_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__branch_exec1_is_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_rd_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__opcode0_rb_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_instr_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__csr_writeback_exception_addr_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_instr_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_lsu_wr_w = VL_RAND_RESET_I(4);
    vlSelf->__PVT__fetch_in_fault_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_instr_rd_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_opcode_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_ack_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__writeback_mem_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_result_e1_exception_w = VL_RAND_RESET_I(6);
    vlSelf->__PVT__fetch0_instr_div_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_fault_fetch_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_info_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_fault_page_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_lsu_data_wr_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_resp_tag_w = VL_RAND_RESET_I(11);
    vlSelf->__PVT__mmu_lsu_req_tag_w = VL_RAND_RESET_I(11);
    vlSelf->__PVT__fetch1_instr_div_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_source_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mul_opcode_opcode_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_d_exec0_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mul_opcode_ra_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__csr_opcode_rb_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__lsu_stall_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_info_is_not_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_csr_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode0_ra_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__branch_info_is_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mul_opcode_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mul_opcode_rb_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_info_is_ret_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec0_is_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mul_opcode_ra_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_instr_exec_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_instr_exec_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__exec1_hold_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__exec0_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__writeback_exec1_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_info_is_jmp_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_rb_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_instr_lsu_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__lsu_opcode_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_lsu_addr_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mul_hold_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_ifetch_accept_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_is_jmp_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_ifetch_invalidate_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_csr_priv_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__lsu_opcode_ra_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_rd_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_instr_mul_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_accept_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_priv_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__div_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_instr_lsu_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__interrupt_inhibit_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_ifetch_error_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch0_instr_csr_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__writeback_mem_exception_w = VL_RAND_RESET_I(6);
    vlSelf->__PVT__fetch1_instr_branch_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_result_e1_write_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_opcode_ra_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode0_opcode_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_d_exec1_priv_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__branch_exec0_is_not_taken_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec1_is_ret_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__writeback_div_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_ra_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mul_opcode_rb_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__mmu_ifetch_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_ifetch_rd_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_fault_page_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_ifetch_flush_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_opcode_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__lsu_opcode_rd_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__lsu_opcode_opcode_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_load_fault_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_satp_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__csr_result_e1_wdata_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode1_ra_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__mmu_lsu_invalidate_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__writeback_exec0_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__csr_opcode_ra_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__ifence_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__exec1_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec0_is_jmp_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch1_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__csr_writeback_wdata_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_accept_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_writeback_write_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__take_interrupt_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_result_e1_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__opcode1_rb_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__fetch0_instr_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__csr_writeback_waddr_w = VL_RAND_RESET_I(12);
    vlSelf->__PVT__fetch1_fault_fetch_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch1_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch0_instr_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_cacheable_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_d_exec0_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode1_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__exec0_hold_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode0_rb_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__opcode0_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__lsu_opcode_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_info_request_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_priv_d_w = VL_RAND_RESET_I(2);
    vlSelf->__PVT__csr_opcode_opcode_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch0_instr_branch_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mul_opcode_invalid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_exec0_is_ret_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_lsu_data_rd_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__writeback_mul_value_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_lsu_flush_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__lsu_opcode_rb_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__mmu_lsu_accept_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__fetch1_instr_rd_valid_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__lsu_opcode_rb_operand_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__mmu_sum_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__branch_info_source_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__branch_info_is_call_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__opcode0_rd_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__branch_d_exec1_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__lsu_opcode_ra_idx_w = VL_RAND_RESET_I(5);
    vlSelf->__PVT__csr_writeback_exception_pc_w = VL_RAND_RESET_I(32);
    vlSelf->__PVT__fetch1_instr_mul_w = VL_RAND_RESET_I(1);
    vlSelf->__PVT__mmu_store_fault_w = VL_RAND_RESET_I(1);
}
